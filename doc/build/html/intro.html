

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Introducing MyGrad &mdash; MyGrad 0+unknown documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/my_theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="MyGrad’s Tensor" href="tensor.html" />
    <link rel="prev" title="Installing MyGrad" href="install.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> MyGrad
          

          
          </a>

          
            
            
              <div class="version">
                0+unknown
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install.html">Installing MyGrad</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introducing MyGrad</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Installing-MyGrad">Installing MyGrad</a></li>
<li class="toctree-l2"><a class="reference internal" href="#A-Simple-Application">A Simple Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Some-Bells-and-Whistles">Some Bells and Whistles</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Advanced-Example">Advanced Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Computational-Graph-Visualization">Computational Graph Visualization</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">MyGrad’s Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="operation.html">MyGrad’s Operation Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_creation.html">Tensor creation routines (<code class="docutils literal notranslate"><span class="pre">mygrad.tensor_creation</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_manipulation.html">Tensor manipulation routines (<code class="docutils literal notranslate"><span class="pre">mygrad.tensor_manip</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg.html">Linear algebra (<code class="docutils literal notranslate"><span class="pre">mygrad.linalg</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="math.html">Mathematical functions (<code class="docutils literal notranslate"><span class="pre">mygrad.math</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="nnet.html">Neural network operations (<code class="docutils literal notranslate"><span class="pre">mygrad.nnet</span></code>)</a></li>
<li class="toctree-l1"><a class="reference internal" href="graph_viz.html">Computational graph visualization(<code class="docutils literal notranslate"><span class="pre">mygrad.computational_graph</span></code>)</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MyGrad</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Introducing MyGrad</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/intro.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="Introducing-MyGrad">
<h1>Introducing MyGrad<a class="headerlink" href="#Introducing-MyGrad" title="Permalink to this headline">¶</a></h1>
<p>MyGrad is a simple, NumPy-centric autograd library. An autograd library
enables you to automatically compute derivatives of mathematical
functions. This library is designed to serve primarily as an education
tool for learning about gradient-based machine learning; it is easy to
install, has a readable and easily customizable code base, and provides
a sleek interface that mimics NumPy. Furthermore, it leverages NumPy’s
vectorization to achieve good performance despite the library’s
simplicity.</p>
<p>This is not meant to be a competitor to libraries like PyTorch (which
<code class="docutils literal notranslate"><span class="pre">mygrad</span></code> most closely resembles) or TensorFlow. Rather, it is meant to
serve as a useful tool for students who are learning about training
neural networks using back propagation.</p>
<div class="section" id="Installing-MyGrad">
<h2>Installing MyGrad<a class="headerlink" href="#Installing-MyGrad" title="Permalink to this headline">¶</a></h2>
<p>To install MyGrad clone <a class="reference external" href="https://github.com/rsokl/MyGrad">this
repository</a> and navigate to the
MyGrad directory, then run:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python setup.py install
</pre></div>
</div>
<p>MyGrad requires <code class="docutils literal notranslate"><span class="pre">numpy</span></code>. It is highly recommended that you utilized
<code class="docutils literal notranslate"><span class="pre">numpy</span></code> built with
<a class="reference external" href="https://en.wikipedia.org/wiki/Math_Kernel_Library">MKL</a> for access
to optimized math routines.</p>
</div>
<div class="section" id="A-Simple-Application">
<h2>A Simple Application<a class="headerlink" href="#A-Simple-Application" title="Permalink to this headline">¶</a></h2>
<p>Let’s use <code class="docutils literal notranslate"><span class="pre">mygrad</span></code> to compute the derivative of <span class="math notranslate nohighlight">\(f(x) = x^2\)</span>
evaluated at <span class="math notranslate nohighlight">\(x = 3\)</span> (which is
<span class="math notranslate nohighlight">\(\frac{df}{dx}\rvert_{x=3} = 2\times 3\)</span>).</p>
<p><code class="docutils literal notranslate"><span class="pre">mygrad.Tensor</span></code> behaves nearly identically to NumPy’s ndarray, in
addition to having the machinery needed to compute the analytic
derivatives of functions. Suppose we want to compute this derivative at
<code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">3</span></code>. We can create a 0-dimensional tensor (a scalar) for x and
compute <code class="docutils literal notranslate"><span class="pre">f(x)</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">mygrad</span> <span class="kn">as</span> <span class="nn">mg</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">mg</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mf">3.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span>
<span class="go">Tensor(9.0)</span>
</pre></div>
</div>
<p>Invoking <code class="docutils literal notranslate"><span class="pre">f.backward()</span></code> instructs <code class="docutils literal notranslate"><span class="pre">mygrad</span></code> to trace through the
computational graph that produced <code class="docutils literal notranslate"><span class="pre">f</span></code> and compute the derivatives of
<code class="docutils literal notranslate"><span class="pre">f</span></code> with respect to all of its independent variables. Thus, executing
<code class="docutils literal notranslate"><span class="pre">f.backward()</span></code> will compute <span class="math notranslate nohighlight">\(\frac{df}{dx} = 2x\)</span> at <span class="math notranslate nohighlight">\(x=3\)</span>,
and will store the resulting value in <code class="docutils literal notranslate"><span class="pre">x.grad</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># triggers computation of `df/dx`</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">grad</span>  <span class="c1"># df/dx = 2x = 6.0</span>
<span class="go">array(6.0)</span>
</pre></div>
</div>
<p>This is the absolute tip of the iceberg. <code class="docutils literal notranslate"><span class="pre">mygrad</span></code> can compute
derivatives of multivariable composite functions of tensor-valued
variables!</p>
</div>
<div class="section" id="Some-Bells-and-Whistles">
<h2>Some Bells and Whistles<a class="headerlink" href="#Some-Bells-and-Whistles" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">mygrad</span></code> supports all of NumPy’s essential features, including:</p>
<ul class="simple">
<li><a class="reference external" href="https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/IntroducingTheNDarray.html">N-dimensional
tensors</a>
that can be reshaped and have their axes transposed</li>
<li><a class="reference external" href="https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/VectorizedOperations.html">vectorization</a></li>
<li><a class="reference external" href="https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/Broadcasting.html">broadcasting</a></li>
<li><a class="reference external" href="https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/BasicIndexing.html">basic and advanced
indexing</a>
(including all varieties of mixed indexing schemes) for both getting
and setting items.</li>
<li>fully-fledged support for
<a class="reference external" href="https://rockt.github.io/2018/04/30/einsum">einsum</a> (including
broadcasting and traces, which are not supported by PyTorch,
TensorFlow, or HIPS-autograd)</li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">mygrad.Tensor</span></code> plays nicely with NumPy-arrays, which behave as
constants when they are used in computational graphs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">mg</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">x</span> <span class="o">**</span> <span class="n">y</span>  <span class="c1"># (2 ** 1, 2 ** 2, 2 ** 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">grad</span>
<span class="go">array([ 1.,  4., 12.])</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">mygrad.nn</span></code> supplies essential functions for machine learning,
including:</p>
<ul class="simple">
<li>N-dimensional convolutions (with striding, dilation, and padding)</li>
<li>N-dimensional pooling</li>
<li>A <a class="reference external" href="https://en.wikipedia.org/wiki/Gated_recurrent_unit">gated recurrent
unit</a> for
sequence-learning (with input-level dropout and variational
hidden-hidden dropout)</li>
</ul>
<p>It leverages a nice <a class="reference external" href="https://github.com/rsokl/MyGrad/blob/a72ebc26acf5c254f59a562c8045698387763a41/mygrad/nnet/layers/utils.py#L6">sliding window
view</a>
function, which produces convolution-style windowed views of
arrays/tensors without making copies of them, to intuitively (and quite
efficiently) perform the neural network-style convolutions and pooling.</p>
</div>
<div class="section" id="Advanced-Example">
<h2>Advanced Example<a class="headerlink" href="#Advanced-Example" title="Permalink to this headline">¶</a></h2>
<p>The following is an example of using <code class="docutils literal notranslate"><span class="pre">mygrad</span></code> to compute the <a class="reference external" href="https://en.wikipedia.org/wiki/Hinge_loss">hinge
loss</a> of classification
scores and to “backpropagate” through (compute the gradient of) this
loss. This example demonstrates some of mygrad’s ability to perform
backpropagation through broadcasted operations, basic indexing, advanced
indexing, and in-place assignments.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mygrad</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">class_scores</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>         <span class="c1"># 100 samples, 10 possible classes for each</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">class_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># correct label for each datum</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">class_labels</span> <span class="o">=</span> <span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class_labels</span><span class="p">)),</span> <span class="n">class_labels</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">correct_class_scores</span> <span class="o">=</span> <span class="n">class_scores</span><span class="p">[</span><span class="n">class_labels</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">Lij</span> <span class="o">=</span> <span class="n">class_scores</span> <span class="o">-</span> <span class="n">correct_class_scores</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.</span>  <span class="c1"># 100x10 margins</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Lij</span><span class="p">[</span><span class="n">Lij</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>      <span class="c1"># scores within the hinge incur no loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Lij</span><span class="p">[</span><span class="n">class_labels</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># the score corresponding to the correct label incurs no loss</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">Lij</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">class_scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># compute mean hinge loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>    <span class="c1"># compute gradient of loss w.r.t all dependent tensors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">class_scores</span><span class="o">.</span><span class="n">grad</span>  <span class="c1"># d(loss)/d(class_scores)</span>
<span class="go">array([[ 0.  ,  0.01,  0.  , -0.04,  0.  ,  0.  ,  0.01,  0.  ,  0.01, 0.01], ...])</span>
</pre></div>
</div>
</div>
<div class="section" id="Computational-Graph-Visualization">
<h2>Computational Graph Visualization<a class="headerlink" href="#Computational-Graph-Visualization" title="Permalink to this headline">¶</a></h2>
<p>MyGrad provides the capability to visually render diagrams of your
computational graphs:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">mygrad</span> <span class="k">as</span> <span class="nn">mg</span>
<span class="kn">from</span> <span class="nn">mygrad.computational_graph</span> <span class="k">import</span> <span class="n">build_graph</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">mg</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">mg</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">f</span> <span class="o">+</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">2</span>

<span class="n">build_graph</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="nb">locals</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre>
<span></span>Out[1]:
</pre></div>
</div>
<div class="output_area docutils container">
<img alt="_images/intro_3_0.svg" src="_images/intro_3_0.svg" /></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">mygrad</span></code> uses <a class="reference external" href="http://www.graphviz.org">Graphviz</a> and a <a class="reference external" href="https://graphviz.readthedocs.io/en/stable/">Python
interface for Graphviz</a>
to render the computational graphs built using tensors. These graphs can
be rendered in Jupyter notebooks, allowing for quick checks of graph
structure, or can be saved to file for later reference.</p>
<p>The dependencies can be installed with:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>conda install graphviz
conda install python-graphviz
</pre></div>
</div>
<p>Big thanks to <a class="reference external" href="https://github.com/petarmhg">Petar Griggs</a> for
implementing these fantastic viz capabilities!</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tensor.html" class="btn btn-neutral float-right" title="MyGrad’s Tensor" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="install.html" class="btn btn-neutral" title="Installing MyGrad" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Ryan Soklaski

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>